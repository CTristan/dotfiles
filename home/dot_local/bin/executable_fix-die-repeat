#!/usr/bin/env bash
#
# fix-die-repeat - Automated check, review, and fix loop using pi
#
# Usage: fix-die-repeat [OPTIONS]
#
# Options:
#   -c, --check-cmd CMD      Command to run checks (default: ./scripts/ci.sh)
#   -n, --max-iters N        Maximum loop iterations (default: 10)
#       --archive-artifacts  Archive existing artifacts to a timestamped folder
#       --no-compact         Skip automatic compaction of large artifacts
#       --pr-review          Enable PR review mode
#   -h, --help               Show this help message
#
# Environment variables:
#   FDR_CHECK_CMD, FDR_MAX_ITERS, FDR_ARCHIVE_ARTIFACTS, FDR_COMPACT_ARTIFACTS, FDR_PR_REVIEW
#

set -euo pipefail

# Defaults (can be overridden by env vars)
FDR_CHECK_CMD="${FDR_CHECK_CMD:-./scripts/ci.sh}"
FDR_MAX_ITERS="${FDR_MAX_ITERS:-10}"
FDR_ARCHIVE_ARTIFACTS="${FDR_ARCHIVE_ARTIFACTS:-0}"
FDR_COMPACT_ARTIFACTS="${FDR_COMPACT_ARTIFACTS:-1}"
FDR_PR_REVIEW="${FDR_PR_REVIEW:-0}"

# Paths
PROJECT_ROOT="$(git rev-parse --show-toplevel 2>/dev/null || pwd)"
FDR_DIR="$PROJECT_ROOT/.fix-die-repeat"
REVIEW_FILE="$FDR_DIR/review.md"
REVIEW_CURRENT_FILE="$FDR_DIR/review_current.md"
BUILD_HISTORY_FILE="$FDR_DIR/build_history.md"
CHECKS_LOG="$FDR_DIR/checks.log"
CHECKS_FILTERED_LOG="$FDR_DIR/checks_filtered.log"
CHECKS_HASH_FILE="$FDR_DIR/.checks_hashes"
PI_LOG="$FDR_DIR/pi.log"

# Context limits for changed files attached to pi
MAX_CONTEXT_FILES=10
MAX_CONTEXT_BYTES=$((200 * 1024))  # 200KB

iteration=0
FDR_START_SHA=""
FDR_START_SHA_FILE="$FDR_DIR/.start_sha"

usage() {
    echo "Usage: $(basename "$0") [OPTIONS]"
    echo ""
    echo "Options:"
    echo "  -c, --check-cmd CMD      Command to run checks (default: ./scripts/ci.sh)"
    echo "  -n, --max-iters N        Maximum loop iterations (default: 10)"
    echo "      --archive-artifacts  Archive existing artifacts to a timestamped folder"
    echo "      --no-compact         Skip automatic compaction of large artifacts"
    echo "      --pr-review          Enable PR review mode"
    echo "  -h, --help               Show this help message"
    echo ""
    echo "Environment variables can also be used:"
    echo "  FDR_CHECK_CMD, FDR_MAX_ITERS, FDR_ARCHIVE_ARTIFACTS, FDR_COMPACT_ARTIFACTS, FDR_PR_REVIEW"
}

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [fdr] $*"
}

error() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [fdr] ERROR: $*" >&2
}

format_duration() {
    local total_seconds=$1
    local hours=$((total_seconds / 3600))
    local minutes=$(((total_seconds % 3600) / 60))
    local seconds=$((total_seconds % 60))

    if [[ $hours -gt 0 ]]; then
        printf "%dh %dm %ds" "$hours" "$minutes" "$seconds"
    elif [[ $minutes -gt 0 ]]; then
        printf "%dm %ds" "$minutes" "$seconds"
    else
        printf "%ds" "$seconds"
    fi
}

# Cleanup and logging on unexpected exit
cleanup() {
    local exit_code=$?
    local end_time
    end_time=$(date +%s)

    if [[ -n "${script_start_time:-}" ]]; then
        local duration=$((end_time - script_start_time))
        log "Total run duration: $(format_duration "$duration")"
    fi

    if [[ $exit_code -ne 0 ]]; then
        error "Script exited unexpectedly with code $exit_code at iteration $iteration"
        if [[ -n "$FDR_START_SHA" ]]; then
            error "To see all changes made: git diff $FDR_START_SHA"
            error "To revert all changes:   git checkout $FDR_START_SHA -- ."
        fi
        if [[ -f "$PI_LOG" ]] && [[ -s "$PI_LOG" ]]; then
            error "=== Last 30 lines of pi.log ==="
            tail -30 "$PI_LOG" >&2
            error "=== End of pi.log excerpt ==="
        fi
    fi
}
trap cleanup EXIT

# ---------------------------------------------------------------------------
# Filter checks.log to extract the most useful failure information.
# Keeps error/warning lines with surrounding context, plus the log tail
# (which typically contains the summary). Writes to CHECKS_FILTERED_LOG.
# ---------------------------------------------------------------------------
filter_checks_log() {
    local max_lines=300
    local context_lines=3
    local tail_lines=80

    if [[ ! -f "$CHECKS_LOG" ]]; then
        return 0
    fi

    local total_lines
    total_lines=$(wc -l < "$CHECKS_LOG")

    # If the log is small enough, just use it directly
    if [[ $total_lines -le $max_lines ]]; then
        cp "$CHECKS_LOG" "$CHECKS_FILTERED_LOG"
        return 0
    fi

    log "Filtering checks.log ($total_lines lines -> ~${max_lines} target)..."

    {
        echo "=== FILTERED CHECK OUTPUT (full log: .fix-die-repeat/checks.log, $total_lines lines) ==="
        echo ""
        echo "--- Error/failure lines with context ---"
        grep -i -n -B "$context_lines" -A "$context_lines" \
            -E '(error[:\[ ]|ERROR[:\[ ]|fatal|FATAL|FAILED|panic|exception|undefined reference|cannot find|no such file|not found|segfault|abort|compilation failed|build failed|assert)' \
            "$CHECKS_LOG" | head -200 || true
        echo ""
        echo "--- Last ${tail_lines} lines ---"
        tail -n "$tail_lines" "$CHECKS_LOG"
    } > "$CHECKS_FILTERED_LOG"

    local filtered_lines
    filtered_lines=$(wc -l < "$CHECKS_FILTERED_LOG")
    log "Filtered checks.log: $total_lines -> $filtered_lines lines"
}

# ---------------------------------------------------------------------------
# Check for oscillation by tracking check output hashes across iterations.
# Prints a warning message if oscillation is detected (empty otherwise).
# ---------------------------------------------------------------------------
check_oscillation() {
    local current_hash="$1"

    if [[ -f "$CHECKS_HASH_FILE" ]]; then
        local prev_match
        prev_match=$(grep "^${current_hash}:" "$CHECKS_HASH_FILE" | tail -1 || true)
        if [[ -n "$prev_match" ]]; then
            local prev_iter
            prev_iter="${prev_match#*:}"
            log "Detected oscillation: iteration $iteration matches iteration $prev_iter"
            echo "WARNING: Check output is IDENTICAL to iteration ${prev_iter}. You are going in CIRCLES. Your previous approach did NOT work — you MUST try a fundamentally DIFFERENT strategy."
        fi
    fi

    # Record this hash
    echo "${current_hash}:${iteration}" >> "$CHECKS_HASH_FILE"
}

# ---------------------------------------------------------------------------
# Fetch PR threads and format them for the agent
# ---------------------------------------------------------------------------
fetch_pr_threads() {
    local branch
    branch=$(git branch --show-current)

    if [[ -z "$branch" ]]; then
        error "Not on a git branch. Skipping PR review."
        return 0
    fi

    log "Fetching PR info for branch: $branch"

    # Check gh auth
    if ! gh auth status >/dev/null 2>&1; then
        error "GitHub CLI not authenticated. Skipping PR review."
        return 0
    fi

    # Get PR info
    local pr_json
    if ! pr_json=$(gh pr view "$branch" --json number,url,headRepository,headRepositoryOwner 2>/dev/null); then
        log "No open PR found for $branch or error fetching PR. Skipping PR review."
        return 0
    fi

    local pr_number pr_url repo_owner repo_name
    pr_number=$(echo "$pr_json" | jq -r .number)
    pr_url=$(echo "$pr_json" | jq -r .url)
    repo_owner=$(echo "$pr_json" | jq -r .headRepositoryOwner.login)
    repo_name=$(echo "$pr_json" | jq -r .headRepository.name)

    log "Found PR #$pr_number ($pr_url). Fetching threads..."

    # GraphQL query to get unresolved threads
    local query='
      query($owner: String!, $repo: String!, $number: Int!) {
        repository(owner: $owner, name: $repo) {
          pullRequest(number: $number) {
            reviewThreads(first: 100) {
              nodes {
                isResolved
                id
                path
                line
                comments(first: 10) {
                  nodes {
                    author { login }
                    body
                  }
                }
              }
            }
          }
        }
      }
    '

    local gql_result
    if ! gql_result=$(gh api graphql -f query="$query" -F owner="$repo_owner" -F repo="$repo_name" -F number="$pr_number"); then
        error "Failed to fetch threads via GraphQL."
        return 0
    fi

    # Parse and format threads using jq
    local threads_output
    threads_output=$(echo "$gql_result" | jq -r '
        .data.repository.pullRequest.reviewThreads.nodes
        | map(select(.isResolved == false))
        | to_entries
        | map(
            "--- Thread #\(.key + 1) ---\n" +
            "ID: \(.value.id)\n" +
            "File: \(.value.path)\n" +
            (if .value.line then "Line: \(.value.line)\n" else "" end) +
            (.value.comments.nodes | map("[\(.author.login // "unknown")]: \(.body)") | join("\n")) +
            "\n"
          )
        | join("\n")
    ')

    if [[ -n "$threads_output" ]]; then
        local count
        count=$(echo "$gql_result" | jq '[.data.repository.pullRequest.reviewThreads.nodes[] | select(.isResolved == false)] | length')

        {
            echo "I've found $count unresolved review threads on PR #$pr_number ($pr_url)."
            echo ""
            echo "Please review each thread, check the associated code, and determine if a fix is required."
            echo "If a fix is needed, apply it. If not, explain why."
            echo ""
            echo "CRITICAL: For each thread below, the 'ID' is the GraphQL thread ID. You MUST use this ID with the available tools:"
            echo " - To resolve a thread after fixing: use 'resolve_pr_threads(threadIds: [\"ID_HERE\"])'"
            echo " - To reply to a thread (e.g. to explain a 'won't fix'): use 'reply_to_thread(threadId: \"ID_HERE\", body: \"...\")'"
            echo ""
            echo "$threads_output"
        } > "$REVIEW_CURRENT_FILE"

        log "Found $count unresolved threads. Added to review queue."
        return 0
    else
        log "No unresolved threads found."
        return 0
    fi
}

# ---------------------------------------------------------------------------
# Compact large persistent artifacts to preserve lessons while reducing noise
# ---------------------------------------------------------------------------
maybe_compact_artifacts() {
    if [[ "$FDR_COMPACT_ARTIFACTS" != "1" && "$FDR_COMPACT_ARTIFACTS" != "true" ]]; then
        return 0
    fi

    local threshold_lines=200
    local needs_compact=0

    for f in "$REVIEW_FILE" "$BUILD_HISTORY_FILE"; do
        if [[ -f "$f" ]] && [[ $(wc -l < "$f") -gt $threshold_lines ]]; then
            needs_compact=1
            break
        fi
    done

    if [[ "$needs_compact" -eq 0 ]]; then
        return 0
    fi

    log "Artifacts exceed ${threshold_lines} lines. Compacting with pi..."

    local compact_args=("-p")
    [[ -f "$REVIEW_FILE" ]] && compact_args+=("@$REVIEW_FILE")
    [[ -f "$BUILD_HISTORY_FILE" ]] && compact_args+=("@$BUILD_HISTORY_FILE")

    # Backup originals
    [[ -f "$REVIEW_FILE" ]] && cp "$REVIEW_FILE" "$REVIEW_FILE.bak"
    [[ -f "$BUILD_HISTORY_FILE" ]] && cp "$BUILD_HISTORY_FILE" "$BUILD_HISTORY_FILE.bak"

    if ! run_pi_safe "${compact_args[@]}" \
        "These are history files from previous fix-die-repeat runs. They have grown large and need compacting.

Your task: read both files and write compacted versions that preserve:
1. Key lessons learned and approaches that FAILED (and why) — these prevent repeated mistakes.
2. Any unresolved or recurring known issues.
3. File paths and areas that have been repeatedly problematic.

Write the compacted review history to '$REVIEW_FILE' and the compacted build history to '$BUILD_HISTORY_FILE'.
Target ~50 lines each. Be concise but do NOT discard failure patterns — those are the most valuable information.
If a file was not provided (doesn't exist), skip it."; then
        log "Compaction failed. Continuing with existing artifacts."
        return 0
    fi

    log "Compaction complete. Backups saved as .bak files in $FDR_DIR."
}

# ---------------------------------------------------------------------------
# Run pi with logging — captures exit code and logs failures
# ---------------------------------------------------------------------------
run_pi() {
    local exit_code=0
    # Run pi, capturing stderr to log file while still showing stdout
    # Use || to capture exit code because process substitution makes ! tricky
    pi "$@" 2> >(tee -a "$PI_LOG" >&2) || exit_code=$?
    
    if [[ $exit_code -ne 0 ]]; then
        error "pi exited with code $exit_code"
        error "pi stderr logged to: $PI_LOG"
        if [[ -f "$PI_LOG" ]]; then
            error "Last 20 lines of pi.log:"
            tail -20 "$PI_LOG" >&2
        fi
        return $exit_code
    fi
    return 0
}

# ---------------------------------------------------------------------------
# Run pi with a single retry on failure. Returns 0 on success, 1 on double
# failure. Prevents a transient pi crash from killing the entire run.
# ---------------------------------------------------------------------------
run_pi_safe() {
    local exit_code=0
    run_pi "$@" || exit_code=$?

    if [[ $exit_code -eq 0 ]]; then
        return 0
    fi

    log "pi failed (exit $exit_code). Retrying once..."

    exit_code=0
    run_pi "$@" || exit_code=$?

    if [[ $exit_code -eq 0 ]]; then
        return 0
    fi

    error "pi failed twice (exit $exit_code). Continuing loop without pi output for this step."
    return 1
}

# ---------------------------------------------------------------------------
# Get changed (staged + unstaged) files, deduplicated, excluding deleted
# files and .fix-die-repeat/ contents.
# ---------------------------------------------------------------------------
get_changed_files() {
    {
        git diff --name-only 2>/dev/null || true
        git diff --cached --name-only 2>/dev/null || true
        git ls-files --others --exclude-standard 2>/dev/null || true
    } | sort -u | while IFS= read -r file; do
        if [[ -f "$PROJECT_ROOT/$file" ]] && [[ "$file" != .fix-die-repeat/* ]]; then
            echo "$file"
        fi
    done
}

# ---------------------------------------------------------------------------
# Collect changed files with size and count limits to avoid context window
# blowout. Prioritizes files mentioned in an optional error log.
# Prints selected filenames to stdout, one per line.
# Usage: read into an array via: mapfile -t arr < <(collect_bounded_context_files ...)
#   or for bash 3.x: while IFS= read -r f; do arr+=("$f"); done < <(...)
# ---------------------------------------------------------------------------
collect_bounded_context_files() {
    local error_log="${1:-}"

    local all_files=()
    while IFS= read -r line; do
        [[ -n "$line" ]] && all_files+=("$line")
    done < <(get_changed_files)

    if [[ ${#all_files[@]} -eq 0 ]]; then
        return 0
    fi

    # If we have an error log, prioritize files mentioned in it
    local prioritized=()
    local rest=()
    if [[ -n "$error_log" ]] && [[ -f "$error_log" ]]; then
        for f in "${all_files[@]}"; do
            if grep -qF "$(basename "$f")" "$error_log" 2>/dev/null; then
                prioritized+=("$f")
            else
                rest+=("$f")
            fi
        done
    else
        rest=("${all_files[@]}")
    fi

    # Merge: prioritized first, then rest
    local ordered=()
    [[ ${#prioritized[@]} -gt 0 ]] && ordered+=("${prioritized[@]}")
    [[ ${#rest[@]} -gt 0 ]] && ordered+=("${rest[@]}")

    local total_bytes=0
    local count=0
    for f in "${ordered[@]}"; do
        if [[ $count -ge $MAX_CONTEXT_FILES ]]; then
            log "Context file limit reached ($MAX_CONTEXT_FILES files). Skipping remaining $((${#ordered[@]} - count)) files." >&2
            break
        fi
        local fsize
        fsize=$(wc -c < "$PROJECT_ROOT/$f" 2>/dev/null || echo 0)
        if [[ $((total_bytes + fsize)) -gt $MAX_CONTEXT_BYTES ]] && [[ $count -gt 0 ]]; then
            log "Context size limit reached (~$((total_bytes / 1024))KB). Skipping remaining files." >&2
            break
        fi
        echo "$f"
        total_bytes=$((total_bytes + fsize))
        count=$((count + 1))
    done

    if [[ $count -lt ${#all_files[@]} ]]; then
        log "Attached ${count} of ${#all_files[@]} changed files (~$((total_bytes / 1024))KB)" >&2
    fi
}

# ---------------------------------------------------------------------------
# Check for large files (>2000 lines) and generate a warning/recommendation
# ---------------------------------------------------------------------------
detect_large_files_warning() {
    local warning=""
    local found_large=0

    for f in "$@"; do
        if [[ -f "$PROJECT_ROOT/$f" ]]; then
            local lines
            lines=$(wc -l < "$PROJECT_ROOT/$f" | tr -d ' ')
            if [[ "$lines" -gt 2000 ]]; then
                if [[ $found_large -eq 0 ]]; then
                    warning+="\nCRITICAL WARNING: The following files are >2000 lines and will be TRUNCATED by the 'read' tool:\n"
                fi
                warning+="- $f ($lines lines)\n"
                found_large=1
            fi
        fi
    done

    if [[ $found_large -eq 1 ]]; then
        warning+="You CANNOT see the bottom of these files. If errors occur there, you are flying blind.\n"
        warning+="STRONGLY RECOMMENDED: Split these files into smaller files or modules to bring them under the 2000-line limit. You cannot reliably fix errors in files you cannot fully read.\n"
        warning+="  - If the file contains tests at the bottom, move them to a separate test file (e.g., tests.rs, test_file.py, file.test.js).\n"
        warning+="  - If it is a large logic file, extract cohesive functionality into separate source files or subfolders.\n"
    fi
    
    echo "$warning"
}

append_review_entry() {
    local timestamp
    timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
    {
        echo "## Iteration $iteration - Review ($timestamp)"
        if [[ -s "$REVIEW_CURRENT_FILE" ]]; then
            cat "$REVIEW_CURRENT_FILE"
        else
            echo "_No issues found._"
        fi
        echo
    } >> "$REVIEW_FILE"
}

append_resolution_entry() {
    local message="$1"
    local timestamp
    timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
    {
        echo "### Iteration $iteration - Resolution ($timestamp)"
        echo "- $message"
        echo
    } >> "$REVIEW_FILE"
}

main() {
    script_start_time=$(date +%s)

    # Argument parsing
    while [[ $# -gt 0 ]]; do
        case "$1" in
            -c|--check-cmd)
                if [[ -n "${2:-}" && ! "$2" =~ ^- ]]; then
                    FDR_CHECK_CMD="$2"
                    shift 2
                else
                    error "Argument for $1 is missing"
                    usage
                    exit 1
                fi
                ;;
            -n|--max-iters)
                if [[ -n "${2:-}" && ! "$2" =~ ^- ]]; then
                    if [[ ! "$2" =~ ^[0-9]+$ ]] || [[ "$2" -le 0 ]]; then
                        error "Invalid value for --max-iters: $2. Must be a positive integer."
                        exit 1
                    fi
                    FDR_MAX_ITERS="$2"
                    shift 2
                else
                    error "Argument for $1 is missing"
                    usage
                    exit 1
                fi
                ;;
            --archive-artifacts)
                FDR_ARCHIVE_ARTIFACTS=1
                shift
                ;;
            --no-compact)
                FDR_COMPACT_ARTIFACTS=0
                shift
                ;;
            --pr-review)
                FDR_PR_REVIEW=1
                shift
                ;;
            -h|--help)
                usage
                exit 0
                ;;
            *)
                error "Unknown option: $1"
                usage
                exit 1
                ;;
        esac
    done

    # Validate final configuration
    if [[ ! "$FDR_MAX_ITERS" =~ ^[0-9]+$ ]] || [[ "$FDR_MAX_ITERS" -le 0 ]]; then
        error "Invalid configuration: FDR_MAX_ITERS must be a positive integer (got '$FDR_MAX_ITERS')"
        exit 1
    fi

    cd "$PROJECT_ROOT"

    # Ensure .fix-die-repeat directory exists and is gitignored
    mkdir -p "$FDR_DIR"
    if [[ -d "$PROJECT_ROOT/.git" ]]; then
        local gitignore="$PROJECT_ROOT/.gitignore"
        if ! grep -qxF '.fix-die-repeat/' "$gitignore" 2>/dev/null; then
            echo '.fix-die-repeat/' >> "$gitignore"
            log "Added .fix-die-repeat/ to .gitignore"
        fi
    fi

    if [[ "$FDR_ARCHIVE_ARTIFACTS" == "1" || "$FDR_ARCHIVE_ARTIFACTS" == "true" ]]; then
        local timestamp
        timestamp=$(date +%Y%m%d_%H%M%S)
        local archive_dir="$FDR_DIR/archive/$timestamp"
        log "Archiving existing artifacts to $archive_dir"
        mkdir -p "$archive_dir"
        find "$FDR_DIR" -mindepth 1 -maxdepth 1 -type f \( -name "*.log" -o -name "*.md" \) -exec mv -- {} "$archive_dir/" \;
    fi

    # Record starting commit SHA for rollback (stored in a file, not a git tag,
    # to avoid any risk of tags being pushed to remotes)
    if git rev-parse HEAD >/dev/null 2>&1; then
        FDR_START_SHA=$(git rev-parse HEAD)
        echo "$FDR_START_SHA" > "$FDR_START_SHA_FILE"
        log "Git checkpoint: $FDR_START_SHA"
    fi

    # Clear per-run files
    > "$PI_LOG"
    > "$CHECKS_HASH_FILE"
    log "Logging pi stderr to: $PI_LOG"

    # Compact large artifacts from previous runs
    maybe_compact_artifacts

    while true; do
        iteration=$((iteration + 1))
        log "===== Iteration $iteration of $FDR_MAX_ITERS ====="

        if [[ $iteration -gt $FDR_MAX_ITERS ]]; then
            error "Maximum iterations ($FDR_MAX_ITERS) exceeded. Could not resolve all issues."
            if [[ -n "$FDR_START_SHA" ]]; then
                error "To see all changes made: git diff $FDR_START_SHA"
                error "To revert all changes:   git checkout $FDR_START_SHA -- ."
            fi
            exit 1
        fi

        # Step 1: Run checks
        log "[Step 1] Running ${FDR_CHECK_CMD} (output: checks.log)..."
        checks_start_time=$(date +%s)
        if bash -c "$FDR_CHECK_CMD" > "$CHECKS_LOG" 2>&1; then
            checks_status=0
        else
            checks_status=$?
        fi
        checks_end_time=$(date +%s)
        checks_duration=$((checks_end_time - checks_start_time))
        log "[Step 1] run_checks duration: $(format_duration "$checks_duration")"

        # Check for oscillation (repeated identical failure output)
        current_checks_hash=$(git hash-object "$CHECKS_LOG" 2>/dev/null || echo "iteration_$iteration")
        repeated_failure_warning=""

        if [[ "$checks_status" -ne 0 ]]; then
            repeated_failure_warning=$(check_oscillation "$current_checks_hash")
        fi

        if [[ $checks_status -eq 0 ]]; then
            log "[Step 2B] Checks passed. Proceeding to review."
        else
            log "[Step 2A] Checks failed. Running pi to fix errors..."

            # Filter the checks log for relevant content
            filter_checks_log

            # Collect context files with limits, prioritizing files in error output
            changed_files=()
            while IFS= read -r f; do
                [[ -n "$f" ]] && changed_files+=("$f")
            done < <(collect_bounded_context_files "$CHECKS_FILTERED_LOG")

            # Construct args for fix step — use filtered log
            fix_checks_args=("-p" "@$CHECKS_FILTERED_LOG")
            if [[ -f "$REVIEW_FILE" ]]; then
                fix_checks_args+=("@$REVIEW_FILE")
            fi
            if [[ -f "$BUILD_HISTORY_FILE" ]]; then
                fix_checks_args+=("@$BUILD_HISTORY_FILE")
            fi
            if [[ ${#changed_files[@]} -gt 0 ]]; then
                for f in "${changed_files[@]}"; do
                    fix_checks_args+=("@$f")
                done
            fi

            # Extract error locations (file:line) and check for common Rust errors
            local error_locations=""
            local missing_field_hint=""
            
            if [[ -f "$CHECKS_FILTERED_LOG" ]]; then
                error_locations=$(grep -oE "[a-zA-Z0-9_/.-]+:[0-9]+" "$CHECKS_FILTERED_LOG" | head -n 20 | sort -u | tr '\n' ' ')
                
                if grep -q "missing field" "$CHECKS_FILTERED_LOG"; then
                     missing_field_hint="HINT: You seem to have a 'missing field' error. You likely updated a struct definition but forgot to update some initializations. Search the codebase for the struct name to find ALL usages (e.g., in tests) and update them."
                fi
            fi

            # Check for large files
            local large_file_warning
            large_file_warning=$(detect_large_files_warning "${changed_files[@]}")

            # Construct prompt for fix step
            fix_checks_prompt="The file .fix-die-repeat/checks_filtered.log contains the failure output from \`${FDR_CHECK_CMD}\` (filtered to error-relevant lines; full log is in .fix-die-repeat/checks.log). "
            if [[ -n "$repeated_failure_warning" ]]; then
                fix_checks_prompt+="$repeated_failure_warning "
            fi
            if [[ -f "$REVIEW_FILE" ]]; then
                 fix_checks_prompt+="I have attached .fix-die-repeat/review.md which contains history of previous iterations. Review it to avoid repeating mistakes. "
            fi
            if [[ -f "$BUILD_HISTORY_FILE" ]]; then
                 fix_checks_prompt+="I have attached .fix-die-repeat/build_history.md which contains a summary of files you modified in previous attempts to fix the build. Use this to avoid repeating ineffective changes. "
            fi
            fix_checks_prompt+="I have also attached the currently changed files for context. "
            
            if [[ -n "$error_locations" ]]; then
                fix_checks_prompt+="\n\nDetected error locations: $error_locations\n"
                fix_checks_prompt+="CRITICAL: If errors are on lines > 2000, you MUST use 'read' with 'offset' to see the code. The 'read' tool truncates large files by default.\n"
            fi
            
            if [[ -n "$missing_field_hint" ]]; then
                fix_checks_prompt+="\n$missing_field_hint\n"
            fi

            if [[ -n "$large_file_warning" ]]; then
                fix_checks_prompt+="$large_file_warning"
            fi
            
            fix_checks_prompt+="Your goal is to FIX the errors. Follow this plan:\n"
            fix_checks_prompt+="1. ANALYZE the log and identify the root cause.\n"
            fix_checks_prompt+="2. PLAN your fix.\n"
            fix_checks_prompt+="3. APPLY the fix using 'edit'.\n"
            fix_checks_prompt+="4. VERIFY with a quick targeted check (e.g., compile the affected file, run the specific failing test). Do NOT run the full \`${FDR_CHECK_CMD}\` — the outer loop will do that."

            if ! run_pi_safe "${fix_checks_args[@]}" "$fix_checks_prompt"; then
                log "pi could not produce a fix this iteration. Continuing to next iteration."
            fi

            # Record history
            {
                echo "## Iteration $iteration Fixes"
                git diff --stat
                echo ""
            } >> "$BUILD_HISTORY_FILE"

            continue
        fi

        # Step 3: Prepare review artifacts
        log "[Step 3] Preparing review artifacts..."
        if [[ ! -f "$REVIEW_FILE" ]]; then
            touch "$REVIEW_FILE"
        fi
        if [[ -f "$REVIEW_CURRENT_FILE" ]]; then
            rm "$REVIEW_CURRENT_FILE"
        fi

        # Step 3.5: Check PR threads if enabled
        if [[ "$FDR_PR_REVIEW" == "1" ]]; then
            log "[Step 3.5] Checking for unresolved PR threads..."
            fetch_pr_threads
            # Disable PR review for subsequent iterations
            FDR_PR_REVIEW=0
        fi

        # Skip local review if we have PR threads to process
        if [[ -s "$REVIEW_CURRENT_FILE" ]]; then
            log "[Step 4] Using PR threads from $REVIEW_CURRENT_FILE for review."
            log "[Step 5] Skipping local file review generation."
        else
            # Step 4: Collect files
            log "[Step 4] Collecting changed and staged files..."
            changed_files=()
            while IFS= read -r f; do
                [[ -n "$f" ]] && changed_files+=("$f")
            done < <(collect_bounded_context_files)

            if [[ ${#changed_files[@]} -eq 0 ]]; then
                log "No changed or staged files found to review. Checks passed. Exiting."
                exit 0
            fi

            log "[Step 4] Found ${#changed_files[@]} file(s) to review"

            # Step 5: Run pi review
            log "[Step 5] Running pi to review files..."
            # Restrict tools to prevent accidental fixes (no edit/bash), but allow grep/find/ls for exploration
            pi_args=("-p" "--tools" "read,write,grep,find,ls")
            for f in "${changed_files[@]}"; do
                pi_args+=("@$f")
            done
            if [[ -f "$REVIEW_FILE" ]]; then
                pi_args+=("@$REVIEW_FILE")
            fi

            if ! run_pi_safe "${pi_args[@]}" "Review all of the provided files for issues. Use .fix-die-repeat/review.md as historical context.
Your task is ONLY to identify and document issues. Do NOT fix them yourself.
Note: You do not have access to 'edit' or 'bash', so you cannot apply fixes even if you wanted to.

Classify issues as:
- [CRITICAL]: Bugs, security flaws, compilation errors, broken logic.
- [NIT]: Style issues, minor optimizations, comments, formatting.

IMPORTANT:
1. ONLY report [NIT] issues if you also find [CRITICAL] issues.
2. If you only find [NIT] issues, report 'No critical issues found' and create an empty .fix-die-repeat/review_current.md.
3. If you find [CRITICAL] issues, report BOTH [CRITICAL] and [NIT] issues.

If you find reportable issues, use the 'write' tool to save them to '.fix-die-repeat/review_current.md' in the project root.
If you find NO reportable issues, use the 'write' tool to create an empty file named '.fix-die-repeat/review_current.md' in the project root."; then
                log "pi review failed. Treating as no issues found."
                touch "$REVIEW_CURRENT_FILE"
            fi
        fi

        append_review_entry

        # Step 6: Analyze review results
        if [[ ! -f "$REVIEW_CURRENT_FILE" ]]; then
            error ".fix-die-repeat/review_current.md was not created by pi. This is unexpected."
            exit 1
        fi

        if [[ -s "$REVIEW_CURRENT_FILE" ]]; then
            log "[Step 6A] Issues found in .fix-die-repeat/review_current.md. Running pi to fix them..."

            fix_args=("-p" "@$REVIEW_CURRENT_FILE")
            if [[ -f "$REVIEW_FILE" ]]; then
                fix_args+=("@$REVIEW_FILE")
            fi

            if ! run_pi_safe "${fix_args[@]}" "Fix all issues documented in .fix-die-repeat/review_current.md. Address each issue mentioned in the file.

Follow this plan:
1. READ the issues in .fix-die-repeat/review_current.md.
2. PLAN your fixes.
3. If an issue is a logic bug, CREATE a unit test to prevent regression.
4. APPLY the fixes using 'edit'.
5. VERIFY with a quick targeted check (e.g., compile the affected file, run the specific failing test). Do NOT run the full \`${FDR_CHECK_CMD}\` — the outer loop will do that.

Ensure that your changes do not re-surface older issues listed in .fix-die-repeat/review.md.
If these issues are PR threads (indicated by 'Thread #ID'), use the 'resolve_pr_threads' tool to mark them resolved on GitHub ONLY after verifying the fix."; then
                log "pi fix failed. Continuing to next iteration to re-check."
            fi
            append_resolution_entry "Fixes applied for .fix-die-repeat/review_current.md; verification pending."

            # Record history for review-fix changes
            {
                echo "## Iteration $iteration Review Fixes"
                git diff --stat
                echo ""
            } >> "$BUILD_HISTORY_FILE"

            continue
        else
            log "[Step 6B] No issues found in .fix-die-repeat/review_current.md."
            append_resolution_entry "No issues found."
        fi

        # Step 7: Done
        if [[ -f "$REVIEW_CURRENT_FILE" ]]; then
            rm "$REVIEW_CURRENT_FILE"
        fi
        # Clean up checkpoint file on success
        rm -f "$FDR_START_SHA_FILE"
        log "[Step 7] Done! All checks passed and no review issues found. .fix-die-repeat/review.md retained."
        exit 0
    done
}

main "$@"
